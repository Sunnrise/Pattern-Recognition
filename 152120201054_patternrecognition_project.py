# -*- coding: utf-8 -*-
"""152120201054_PatternRecognition_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FOHjD7JM7Z0pdx9gyndkGx-zeqQCsbwZ
"""

!pip install librosa scikit-learn matplotlib pandas numpy

"""# Kaggle API key import"""

from google.colab import files
files.upload()  # kaggle.json dosyasını seç

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets download -d uwrfkaggler/ravdess-emotional-speech-audio
!unzip ravdess-emotional-speech-audio.zip -d ravdess/

df['label'].value_counts()

"""# Gerekli Kütüphaneler"""

import os
import librosa
import numpy as np
import pandas as pd
from tqdm import tqdm

""" # Öznitelik Çıkarma Fonksiyonu"""

def extract_features(file_path):
    y, sr = librosa.load(file_path, sr=None)
    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)
    chroma = librosa.feature.chroma_stft(y=y, sr=sr)
    zcr = librosa.feature.zero_crossing_rate(y)
    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)

    features = np.hstack([
        np.mean(mfccs, axis=1),
        np.std(mfccs, axis=1),
        np.mean(chroma, axis=1),
        np.mean(zcr),
        np.mean(spectral_centroid)
    ])
    return features

"""# Etiket çıkarma ve tüm dosyalar için işlem"""

import re

data = []
labels = []

emotion_map = {
    '01': 'neutral',
    '02': 'calm',
    '03': 'happy',
    '04': 'sad',
    '05': 'angry',
    '06': 'fearful',
    '07': 'disgust',
    '08': 'surprised'
}

for folder in tqdm(os.listdir("ravdess/")):
    if folder.startswith("Actor"):
        actor_folder = os.path.join("ravdess", folder)
        for file in os.listdir(actor_folder):
            if file.endswith(".wav"):
                emotion_code = file.split("-")[2]  # 3. parça: '01' to '08'
                emotion = emotion_map.get(emotion_code)
                if emotion:
                    file_path = os.path.join(actor_folder, file)
                    features = extract_features(file_path)
                    data.append(features)
                    labels.append(emotion)


df = pd.DataFrame(data)
df['label'] = labels

df['label'].value_counts()

"""# Model Eğitimi ve Karşılaştırması"""

# Train-Test Ayrımı
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

X = df.drop('label', axis=1)
y = df['label']

# Encode labels
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y_encoded = le.fit_transform(y)

# Split
X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)

# Scale
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Her sınıf için en az 20 örneği olanları al
min_samples = 20
df_filtered = df.groupby('label').filter(lambda x: len(x) >= min_samples)

# Etiketleri tekrar encode et
X = df_filtered.drop('label', axis=1)
y = df_filtered['label']
le = LabelEncoder()
y_encoded = le.fit_transform(y)

# Train-test split (stratify ZORUNLU)
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

X_train, X_test, y_train, y_test = train_test_split(
    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
)

# Standardize et
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Yeni sınıf sayısını kontrol et
print(f"Yeni sınıf sayısı: {len(np.unique(y_train))}")

# Model Eğitimi (5 Sınıflandırıcı)
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier

models = {
    "SVM": SVC(probability=True),
    "Random Forest": RandomForestClassifier(),
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "KNN": KNeighborsClassifier(),
    "Gradient Boosting": GradientBoostingClassifier()
}

# Model Eğitimi ve Performans Ölçümü
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report

n_models = len(models)
fig, axes = plt.subplots(1, n_models, figsize=(6 * n_models, 8))  # Make taller for space

for ax, (name, model) in zip(axes, models.items()):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    acc = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred, average='weighted')
    cm = confusion_matrix(y_test, y_pred)

    # Draw confusion matrix
    sns.heatmap(cm, annot=True, fmt='d',
                xticklabels=le.classes_,
                yticklabels=le.classes_,
                cmap='Blues', ax=ax)

    # Fix label orientations
    ax.set_xticklabels(le.classes_, rotation=0, fontsize=9)
    ax.set_yticklabels(le.classes_, rotation=0, fontsize=9)

    # Axis labels and title
    ax.set_xlabel("Predicted")
    ax.set_ylabel("True")
    ax.set_title(f"{name}", fontsize=12)

    # Add classification report under the plot
    report_text = classification_report(y_test, y_pred, target_names=le.classes_, digits=2)
    ax.text(0.5, -0.55, f"Classification Report:\n{report_text}",
            transform=ax.transAxes,
            fontsize=9,
            ha='center',
            va='top',
            family='monospace')

plt.tight_layout()
plt.suptitle("Confusion Matrices + Reports (Horizontal Class Labels)", fontsize=16, y=1.08)
plt.show()

import numpy as np
unique_classes, counts = np.unique(y_train, return_counts=True)
for label, count in zip(unique_classes, counts):
    print(f"Class {label} ({le.inverse_transform([label])[0]}): {count} örnek")

# Sonuçların Karşılaştırılması (Tablo)
import pandas as pd

summary = pd.DataFrame({
    model: {
        'Accuracy': res['accuracy'],
        'F1 Score': res['f1_score']
    }
    for model, res in results.items()
}).T

summary = summary.sort_values(by='F1 Score', ascending=False)
display(summary)

from matplotlib import pyplot as plt
summary['Accuracy'].plot(kind='line', figsize=(8, 4), title='Accuracy')
plt.gca().spines[['top', 'right']].set_visible(False)

from matplotlib import pyplot as plt
summary['F1 Score'].plot(kind='line', figsize=(8, 4), title='F1 Score')
plt.gca().spines[['top', 'right']].set_visible(False)

from sklearn.preprocessing import label_binarize

# Tüm sınıfları al
class_names = le.classes_
y_test_bin = label_binarize(y_test, classes=range(len(class_names)))
n_classes = y_test_bin.shape[1]

from sklearn.metrics import roc_curve, auc
from sklearn.multiclass import OneVsRestClassifier
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
from itertools import cycle

plt.figure(figsize=(10, 8))
colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red'])

for name, model in models.items():
    if hasattr(model, "predict_proba"):
        clf = OneVsRestClassifier(model)
        clf.fit(X_train, y_train)
        y_score = clf.predict_proba(X_test)

        # ROC curve for each class
        fpr = dict()
        tpr = dict()
        roc_auc = dict()
        for i in range(n_classes):
            fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])
            roc_auc[i] = auc(fpr[i], tpr[i])

        # Average ROC
        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))
        mean_tpr = np.zeros_like(all_fpr)
        for i in range(n_classes):
            mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])
        mean_tpr /= n_classes

        mean_auc = auc(all_fpr, mean_tpr)

        plt.plot(all_fpr, mean_tpr, label=f'{name} (AUC = {mean_auc:.2f})')

plt.plot([0, 1], [0, 1], 'k--', label='Chance')
plt.title('ROC Curves for Multi-class Classification')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend()
plt.grid(True)
plt.show()