# -*- coding: utf-8 -*-
"""152120201054_PatternRecognitionHW_3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BWRS3uOVosaPVCaZtP7wHKPOSTkZ_xUb
"""

import zipfile

zip_path = "/content/HW3_new.zip"  # Replace with your actual file name
extract_path = "/content/extracted_data"  # Define where to extract

# Extract ZIP
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print(f"Files extracted to: {extract_path}")

# ================== STEP 1: SETUP & IMPORT LIBRARIES ==================
import os
import numpy as np
import cv2
import zipfile
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.utils import shuffle
from google.colab import files

dataset_path = "/content/extracted_data/CaltechTiny3"

# Define categories (2 classes)
categories = ["flamingo", "pizza"]

# Initialize data and labels
train_data, train_labels = [], []
test_data, test_labels = [], []

# Load images from "train" and "test" folders
for category in categories:
    train_folder = os.path.join(dataset_path, "train", category)  # Train folder path
    test_folder = os.path.join(dataset_path, "test", category)  # Test folder path
    class_label = categories.index(category)  # Assign labels: Motorbikes -> 0, hawksbill -> 1

    # Load training images
    for img_name in os.listdir(train_folder):
        img_path = os.path.join(train_folder, img_name)
        img = cv2.imread(img_path)
        if img is None:
            continue
        img = cv2.resize(img, (128, 128))  # Resize to 128x128
        img = img.flatten()  # Convert to 1D vector (1x49152)
        train_data.append(img)
        train_labels.append(class_label)

    # Load testing images
    for img_name in os.listdir(test_folder):
        img_path = os.path.join(test_folder, img_name)
        img = cv2.imread(img_path)
        if img is None:
            continue
        img = cv2.resize(img, (128, 128))  # Resize to 128x128
        img = img.flatten()  # Convert to 1D vector (1x49152)
        test_data.append(img)
        test_labels.append(class_label)

# Convert lists to NumPy arrays
X_train, y_train = np.array(train_data, dtype=np.float32), np.array(train_labels)
X_test, y_test = np.array(test_data, dtype=np.float32), np.array(test_labels)

print(f"Training samples: {len(X_train)}, Testing samples: {len(X_test)}")

# ================== STEP 4: DEFINE PERCEPTRON FUNCTIONS ==================
def sigmoidp(x):
    return 1 / (1 + np.exp(-np.clip(x, -500, 500)))  # Prevent overflow

def Swish(x):
    return x * sigmoidp(x)

def dSwish(x):
    swish_x = Swish(x)
    return swish_x + sigmoidp(x) * (1 - swish_x)

def trainPerceptron(inputs, t, rho=0.001, iterNo=2000):  # Increased learning rate & iterations
    inputs = np.hstack([inputs, np.ones((inputs.shape[0], 1))])  # Add bias term
    n_features = inputs.shape[1]
    weights = np.random.randn(n_features) * 0.01  # Small weight initialization

    for _ in range(iterNo):
        inputs, t = shuffle(inputs, t)  # Shuffle for better training
        for i in range(len(inputs)):
            x = inputs[i]
            target = t[i]

            # Feed-forward
            y = np.dot(weights, x)
            o = Swish(y)

            # Compute error
            error = target - o
            gradient = error * dSwish(y) * x  # Gradient computation

            # Update weights
            weights += rho * gradient

    np.save("weights.npy", weights)  # Save weights
    return weights

# ================== STEP 5: TRAIN PERCEPTRON ==================
print("Training perceptron...")
weights = trainPerceptron(X_train, y_train)
print("Training completed.")

# ================== STEP 6: TEST PERCEPTRON ==================
def testPerceptron(sample_test, weights):
    sample_test = np.hstack([sample_test, np.ones((sample_test.shape[0], 1))])  # Add bias
    y = np.dot(sample_test, weights)
    predictions = Swish(y)
    return (predictions >= 0.5).astype(int)  # Convert to binary labels

# Load trained weights
weights = np.load("weights.npy")

# Predict on test data
y_pred = testPerceptron(X_test, weights)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Test Accuracy: {accuracy:.4f}")